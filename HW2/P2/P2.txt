# Describe your experiments with the three scales of locking, including suggestions for a good N to choose for medium grained
locking in the two cases explored (uncorrelated and correlated transfers) and justification for that choice.

For the case of uncorrelated transfers, the serial code the clear winner in terms of taking fastest time to run as compared
to the various parallel methods. This is probably because both the fine and medium grained locking approach incurs such a 
large computational overhead and complexity cost such that the additional benefit of concurrency and using 4 threads does
not make up for it. Even though the serial approach does not make use of concurrency at all, it is simple and does not 
incur extra scheduling computational overhead, and works better in the case of uncorrelated data transfers.

Serial uncorrelated: 0.341490030289 seconds
Fine grained uncorrelated: 7.19965696335 seconds
Medium grained uncorrelated: 8.84274315834 seconds 

Serial correlated: 0.402601003647 seconds
Fine grained correlated: 6.42255997658 seconds
Medium grained correlated: 10.71063399315 seconds

Exploring different values of N and comparing correlated and uncorrelated data transfer patterns resulted in the graph P2.png. The graph shows that for medium-grained computations, performance decreases as N increases. This is because of the fact that as N increases, more elements in the count array fall under the same lock and the acquiring and releasing of locks become less frequent/there are more collisions. Hence, the most ideal value for N for correlated would be 1 (fine-grained) whereas that for uncorrelated is somewhere in the range of 40-60.